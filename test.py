# -*- coding: utf-8 -*-
"""ML1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Bwrk3saMNaH7Uvem8wGY3vUJYlnoa96w
"""

import pandas as pd
import numpy as np

df1=pd.read_csv('Dataset/data_T.csv') 
print(df1)
df2=pd.read_csv('Dataset/data_X.csv') 
print(df2)

data = np.hstack((df1.to_numpy(),df2[df2.columns[1:8]].to_numpy()))
data_shuffle = data

#打亂data
np.random.shuffle(data_shuffle)

#counting variables
num_data = 500
num_train = 400
num_val = 100

#Data preprocessing

#取合併後的第一行target值也就是chance of admit
y = data_shuffle[:,1]

y = y.astype('double')

#對target做normalization
tar = (y-y.min())/(y.max()-y.min())
tmax = y.max()
tmin = y.min()

#取出input值(7 features)
inputss = data_shuffle[:,2:]
inputss = inputss.astype('double')

#對input做normalization
inputs = (inputss-inputss.min(axis=0))/(inputss.max(axis=0)-inputss.min(axis=0))

# Feature selection
#M=1
#選擇 training sets = 400, valdation set = 100

basis1 = np.hstack([np.full((500,1),1),inputs])



#z = np.reshape(np.array(np.var(basis1[:,1:])),(1,1))
#mean1 = np.reshape(np.mean(basis1[:,1:],axis=0),(1,7))
#basis1[:,1:] = np.exp((basis1[:,1:]-np.dot(np.full((500,1),1),mean1))**2*np.diag(1/z)*(-0.5))


basis1_train = basis1[0:400,:]
basis1_valid = basis1[400:,:]
tar_train = tar[0:400]
tar_valid = tar[400:]

print(np.shape(basis1))

temp = np.dot(basis1_train.T,basis1_train)
temp = np.linalg.inv(temp)
temp = temp.dot(basis1_train.T)
temp = temp.dot(tar_train)
w_p1 = temp

#y = φW
valid1 = basis1_train.dot(w_p1) 
#還原output(因為input之前normalize過)並計算error
#error1_t = np.sum(((val1-tar_t)*(tmax-tmin)+tmin)**2)/2/400
error1_train = np.sum((valid1-tar_train)**2)/2/400

valid2 = basis1_valid.dot(w_p1)
#error1_v = np.sum(((val2-tar_v)*(tmax-tmin)+tmin)**2)/2/100
error1_valid = np.sum((valid2-tar_valid)**2)/2/100


print(((2*error1_train)/400)**(0.5))
print(((2*error1_valid)/100)**(0.5))
w_p1

print(np.shape(w_p1))

